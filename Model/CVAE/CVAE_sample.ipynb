{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7liWoc9QEgCT",
        "outputId": "1c6a5f66-5abe-4e4a-e3de-5e24fa6c0f5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-13 15:31:07.553490: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-02-13 15:31:07.794157: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-13 15:31:07.794209: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-13 15:31:07.806201: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-13 15:31:07.837613: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-02-13 15:31:07.838007: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-02-13 15:31:09.151752: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import csv\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import contextlib\n",
        "from PIL import Image\n",
        "plt.rcParams['figure.dpi'] = 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cab88ObLEgCX"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Eh-BPPt5EgCa"
      },
      "outputs": [],
      "source": [
        "class CVAE(tf.keras.Model):\n",
        "  \"\"\"Variational autoencoder.\"\"\"\n",
        "\n",
        "  def __init__(self, latent_dim, num_classes,  kernel_size = 3):\n",
        "    super(CVAE, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "    self.encoder = tf.keras.Sequential(\n",
        "        [\n",
        "          tf.keras.layers.Conv2D(32, (kernel_size, kernel_size), activation='relu', padding=\"same\", input_shape=(32, 32, 1)),\n",
        "          tf.keras.layers.BatchNormalization(),\n",
        "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "          tf.keras.layers.Dropout(0.3),\n",
        "          tf.keras.layers.Conv2D(64, (kernel_size, kernel_size), padding=\"same\", activation='relu'),\n",
        "          tf.keras.layers.BatchNormalization(),\n",
        "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "          tf.keras.layers.Dropout(0.3),\n",
        "          tf.keras.layers.Conv2D(64, (kernel_size, kernel_size), padding=\"same\", activation='relu'),\n",
        "          tf.keras.layers.BatchNormalization(),\n",
        "          tf.keras.layers.Dropout(0.3),\n",
        "          tf.keras.layers.Flatten(),\n",
        "          tf.keras.layers.Dense(latent_dim + latent_dim)\n",
        "          ]\n",
        "     )\n",
        "\n",
        "    self.decoder = tf.keras.Sequential(\n",
        "        [\n",
        "          tf.keras.layers.InputLayer(input_shape=(latent_dim + num_classes,)),\n",
        "          tf.keras.layers.Dense(units=8*8*32, activation=tf.nn.relu),\n",
        "          tf.keras.layers.Reshape(target_shape=(8, 8, 32)),\n",
        "          tf.keras.layers.Conv2DTranspose(filters=64,kernel_size=kernel_size, strides=(1, 1),padding=\"same\",activation='relu'),\n",
        "          tf.keras.layers.UpSampling2D(size=(2, 2)),\n",
        "          tf.keras.layers.Conv2DTranspose(filters=64,kernel_size=kernel_size, strides=(1, 1),padding=\"same\",activation='relu'),\n",
        "          tf.keras.layers.UpSampling2D(size=(2, 2)),\n",
        "          tf.keras.layers.Conv2DTranspose(filters=32,kernel_size=kernel_size, strides=(1, 1),padding=\"same\",activation='relu'),\n",
        "          tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=kernel_size, strides=(1, 1), padding=\"same\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "  def call(self, inputs):\n",
        "    image, temp = inputs\n",
        "    mean, logvar = self.encode(image)\n",
        "    z = self.reparameterize(mean, logvar)\n",
        "    z = tf.concat([z, temp], axis=1)\n",
        "    reconstructed = self.decode(z)\n",
        "    return reconstructed\n",
        "\n",
        "  @tf.function\n",
        "  def sample(self, eps=None):\n",
        "    if eps is None:\n",
        "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
        "    return self.decode(eps, apply_sigmoid=True)\n",
        "\n",
        "  def encode(self, x):\n",
        "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
        "    return mean, logvar\n",
        "\n",
        "  def reparameterize(self, mean, logvar):\n",
        "    eps = tf.random.normal(shape=mean.shape)\n",
        "    return eps * tf.exp(logvar * .5) + mean\n",
        "\n",
        "  def decode(self, z, apply_sigmoid=False):\n",
        "    logits = self.decoder(z)\n",
        "    if apply_sigmoid:\n",
        "      probs = tf.sigmoid(logits)\n",
        "      return probs\n",
        "    return logits\n",
        "\n",
        "\n",
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "  log2pi = tf.math.log(2. * np.pi)\n",
        "  return tf.reduce_sum(\n",
        "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
        "      axis=raxis)\n",
        "\n",
        "\n",
        "def compute_loss(model, x):\n",
        "  image, temp = x\n",
        "  mean, logvar = model.encode(image)\n",
        "  z = model.reparameterize(mean, logvar)\n",
        "  z_t = tf.concat([z, temp], axis=1)\n",
        "  x_logit = model.decode(z_t)\n",
        "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=image)\n",
        "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
        "  logpz = log_normal_pdf(z, 0., 0.)\n",
        "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, x, optimizer):\n",
        "  \"\"\"Executes one training step and returns the loss.\n",
        "\n",
        "  This function computes the loss and gradients, and uses the latter to\n",
        "  update the model's parameters.\n",
        "  \"\"\"\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = compute_loss(model, x)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqqVHZudEgCe"
      },
      "source": [
        "# Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ab2VvreDEgCg"
      },
      "outputs": [],
      "source": [
        "def sample(num_examples_to_generate, model, temp_vector,latent_dim = 200):\n",
        "    random_mean = tf.random.normal(\n",
        "        shape=[num_examples_to_generate, latent_dim])\n",
        "    log_var = tf.random.normal(\n",
        "        shape=[num_examples_to_generate, latent_dim])\n",
        "    z = model.reparameterize(random_mean, log_var)\n",
        "    z_t = tf.concat([z, temp_vector], axis=1)\n",
        "    predictions = model.sample(z_t)\n",
        "    return predictions"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
