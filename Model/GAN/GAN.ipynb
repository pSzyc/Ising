{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ising Model GAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 10:07:37.214049: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-16 10:07:37.252958: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-16 10:07:37.252988: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-16 10:07:37.253927: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-16 10:07:37.259767: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-16 10:07:37.260443: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-16 10:07:38.269645: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "import time\n",
    "from IPython import display\n",
    "from model import make_discriminator_model, make_generator_model, train_step\n",
    "from pathlib import Path\n",
    "data_path = Path(\"../../GetData/Python/Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from input_pipeline import dataset_tfrecord_pipeline\n",
    "\n",
    "class DataIterator:\n",
    "    def __init__(self, datasets):\n",
    "        self.datasets = datasets\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.data_iterators = [iter(data) for data in self.datasets]\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        data_list = []\n",
    "        temp_list = []\n",
    "        for index, data_iterator in enumerate(self.data_iterators):\n",
    "            data = next(data_iterator)\n",
    "            data_list.append(data)\n",
    "            temp = np.zeros((data.shape[0], len(self.data_iterators)))\n",
    "            temp[:, index] = 1\n",
    "            temp_list.append(temp)\n",
    "        temps = tf.concat(temp_list, axis=0)\n",
    "        data = tf.concat(data_list, axis=0)\n",
    "        return data, temps\n",
    "        \n",
    "def cvae_dataset(data_dir, temps, batch_size=100, flatten=False):\n",
    "    if isinstance(data_dir, str):\n",
    "        data_dir = Path(data_dir)\n",
    "    \n",
    "    assert batch_size % len(temps) == 0, \"Batch size must be divisible by the number of temperatures\"\n",
    "\n",
    "    datasets = []\n",
    "    for temp in temps:\n",
    "        dataset = dataset_tfrecord_pipeline(data_dir / f\"Data{temp:.1f}.tfrecord\", flatten=flatten, batch_size=batch_size // len(temps))\n",
    "        datasets.append(dataset)\n",
    "    gen = DataIterator(datasets)\n",
    "    dataset = tf.data.Dataset.from_generator(lambda: gen, output_signature = (tf.TensorSpec(shape=(None, 32, 32, 1), dtype=tf.float32), tf.TensorSpec(shape=(None, len(temps)), dtype=tf.float32)))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = [2.0, 2.5, 2.9]\n",
    "batch_size = 120\n",
    "train_dataset = cvae_dataset(data_path, temps, batch_size=batch_size, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Format it to include date, hour, and minutes\n",
    "formatted_datetime = current_datetime.strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "results = Path(\"results/\" + formatted_datetime)\n",
    "results.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  predictions = tf.round(model(test_input, training=False))\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "  \n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0])\n",
    "      plt.axis('off')\n",
    "        \n",
    "  plt.savefig(results / 'image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()\n",
    "\n",
    "def train(dataset, epochs, batch_size, gen_loss_log, disc_loss_log):  \n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for images in tqdm(dataset): train_step(images, gen_loss_log, disc_loss_log, batch_size, noise_dim, generator, discriminator, generator_optimizer, discriminator_optimizer)\n",
    "\n",
    "    display.clear_output(wait=True) \n",
    "    generate_and_save_images(\n",
    "      generator,\n",
    "      epoch + 1,\n",
    "      random_vector_for_generation\n",
    "    ) \n",
    "    print (f\"Time taken for epoch {epoch} is {time.time()- start} sec\")\n",
    "    \n",
    "\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "random_vector_for_generation = tf.random.normal([num_examples_to_generate,\n",
    "                                                 noise_dim])\n",
    "generator = make_generator_model(len(temps))\n",
    "discriminator = make_discriminator_model()\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=2\n",
    "gen_loss_log=[]\n",
    "disc_loss_log=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:18,  1.44s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/IPython/core/magics/execution.py\", line 1332, in time\n",
      "    out = eval(code, glob, local_ns)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<timed eval>\", line 1, in <module>\n",
      "  File \"/tmp/ipykernel_102682/2590414623.py\", line 18, in train\n",
      "    for images in tqdm(dataset): train_step(images, gen_loss_log, disc_loss_log, batch_size, noise_dim, generator, discriminator, generator_optimizer, discriminator_optimizer)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/Code/FUW/Ising/Model/GAN/model.py\", line 74, in train_step\n",
      "    generated_images = generator(noise_t, training=True)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/keras/src/engine/training.py\", line 590, in __call__\n",
      "    return super().__call__(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/keras/src/engine/sequential.py\", line 398, in call\n",
      "    return super().call(inputs, training=training, mask=mask)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 515, in call\n",
      "    return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n",
      "    outputs = node.layer(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/keras/src/layers/core/dense.py\", line 241, in call\n",
      "    outputs = tf.matmul(a=inputs, b=self.kernel)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py\", line 142, in wrapper\n",
      "    return op(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py\", line 1260, in op_dispatch_handler\n",
      "    return dispatch_target(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/tensorflow/python/ops/math_ops.py\", line 3842, in matmul\n",
      "    return gen_math_ops.mat_mul(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 6171, in mat_mul\n",
      "    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1155, in get_records\n",
      "    FrameInfo(\n",
      "  File \"/home/ps/.local/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 780, in __init__\n",
      "    ix = inspect.getsourcelines(frame)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib64/python3.11/inspect.py\", line 1244, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "                  ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib64/python3.11/inspect.py\", line 1081, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(train_dataset, EPOCHS, batch_size, gen_loss_log, disc_loss_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([batch_size, noise_dim])\n",
    "images, temps = data\n",
    "noise_t = tf.concat([noise, temps], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss of the generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(np.asarray(disc_loss_log), color='tab:red')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Discriminator Loss', color='tab:red')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(np.asarray(gen_loss_log), color='tab:blue')\n",
    "ax2.set_ylabel('Generator Loss', color='tab:blue')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_weights('generator_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "predictions = generator(random_vector_for_generation, training=False)\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    spins = np.random.binomial(1, predictions[i, :, :])\n",
    "    plt.imshow(spins)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
