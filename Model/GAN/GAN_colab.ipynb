{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJIIRCwhEYGj"
      },
      "source": [
        "## Ising Model GAN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/pSzyc/Ising/main/Model/GAN/model.py\n",
        "!wget https://raw.githubusercontent.com/pSzyc/Ising/main/Model/input_pipeline.py"
      ],
      "metadata": {
        "id": "trSZesBRLFA5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d743417-f45e-4935-aa2e-a02e83e3e8ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-25 12:24:37--  https://raw.githubusercontent.com/pSzyc/Ising/main/Model/GAN/model.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2506 (2.4K) [text/plain]\n",
            "Saving to: ‘model.py’\n",
            "\n",
            "model.py            100%[===================>]   2.45K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-25 12:24:38 (49.9 MB/s) - ‘model.py’ saved [2506/2506]\n",
            "\n",
            "--2023-11-25 12:24:38--  https://raw.githubusercontent.com/pSzyc/Ising/main/Model/input_pipeline.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2226 (2.2K) [text/plain]\n",
            "Saving to: ‘input_pipeline.py’\n",
            "\n",
            "input_pipeline.py   100%[===================>]   2.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-25 12:24:38 (40.1 MB/s) - ‘input_pipeline.py’ saved [2226/2226]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULt_ebFhEYGl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import time\n",
        "from IPython import display\n",
        "from input_pipeline import dataset_colab_pipeline\n",
        "from model import make_discriminator_model, make_generator_model, generator_loss, discriminator_loss\n",
        "import csv\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = \"drive/MyDrive/Licencjat\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN2Jr9L7EYGm"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qV5ZO7laEYGn"
      },
      "outputs": [],
      "source": [
        "trainset_path = f\"{data_path}/Trainset.npy\"\n",
        "testset_path =  f\"{data_path}/Testset.npy\"\n",
        "batch_size = 32\n",
        "train_set = dataset_colab_pipeline(trainset_path, flatten=False, batch_size=batch_size)\n",
        "test_set = dataset_colab_pipeline(testset_path, flatten=False, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E--E6qcuEYGn"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXCWdZwREYGn"
      },
      "outputs": [],
      "source": [
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq11JovvEYGn"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4AzdPLDEYGn"
      },
      "source": [
        "## Setup training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-pRYEuuEYGo"
      },
      "outputs": [],
      "source": [
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# We'll re-use this random vector used to seed the generator so\n",
        "# it will be easier to see the improvement over time.\n",
        "random_vector_for_generation = tf.random.normal([num_examples_to_generate,\n",
        "                                                 noise_dim])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVtGI4idEYGo"
      },
      "outputs": [],
      "source": [
        "def train_step(images, gen_loss_log, disc_loss_log):\n",
        "      noise = tf.random.normal([batch_size, noise_dim])\n",
        "\n",
        "      with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        generated_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(generated_output)\n",
        "        gen_loss_log.append(gen_loss)\n",
        "        disc_loss = discriminator_loss(real_output, generated_output)\n",
        "        disc_loss_log.append(disc_loss)\n",
        "\n",
        "      gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7ybuluhEYGo"
      },
      "outputs": [],
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  predictions = tf.round(model(test_input, training=False))\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(np.rint(predictions[i, :, :, 0]))\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4ulPvxkEYGo"
      },
      "outputs": [],
      "source": [
        "def train(dataset, epochs, gen_loss_log, disc_loss_log):\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for images in tqdm(dataset): train_step(images, gen_loss_log, disc_loss_log)\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(\n",
        "      generator,\n",
        "      epoch + 1,\n",
        "      random_vector_for_generation\n",
        "    )\n",
        "    print (f\"Time taken for epoch {epoch} is {time.time()- start} sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzLVkB79EYGp"
      },
      "source": [
        "## Train the GAN!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9upxctybEYGp"
      },
      "outputs": [],
      "source": [
        "EPOCHS=30\n",
        "gen_loss_log=[]\n",
        "disc_loss_log=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1vDb-pqEYGp"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "train(train_set, EPOCHS,gen_loss_log,disc_loss_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeOtnaSTEYGp"
      },
      "source": [
        "## Plot the loss of the generator and discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ngg7pbY-EYGq"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.asarray(gen_loss_log))\n",
        "plt.plot(np.asarray(disc_loss_log))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abnLiPeZEYGq"
      },
      "outputs": [],
      "source": [
        "predictions = generator(random_vector_for_generation, training=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data in test_set.take(1):\n",
        "  sns.heatmap(data[0, :, :, 0])"
      ],
      "metadata": {
        "id": "ce5CTI08U9iE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBRgrS7zEYGq"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(predictions[0, :, :, 0]>0)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}